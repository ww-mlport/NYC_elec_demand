library(tidyverse)
library(tidyr)
library(dplyr)
library(zoo)
library(lubridate)
library(ggplot2)
library(corrplot)
wd <- "C:/Users/wwell/Documents/GitHub/demand_prediction_local/data/"
weather <- read.csv(paste0 (wd, "NOAA_New York_Weather Data.csv"))
demand <- read.csv(paste0 (wd, "Demand_for_New_York_Independent_System_Operator_(NYIS)_hourly_-_UTC_time.csv"), skip=4)
#print(colnames(weather))
weather_filtered <- weather %>%
select(-starts_with("Daily"), -starts_with("Monthly"), -starts_with("ShortDuration"),-starts_with("Backup")) %>%
select(-c(1,3:13,17,21,22,26,29:36))
print(colnames(weather_filtered))
# create date and hour columns
weather_filtered <- weather_filtered %>%
separate(DATE, into = c("date", "hour"), sep = "T")
weather_filtered$hour <- substr(weather_filtered$hour, 1, 2)
# remove duplicates for the date and hour columns
weather_filtered <- weather_filtered[!duplicated(weather_filtered[, c("date", "hour")], fromFirst = TRUE), ]
# convert columns to numeric
weather_filtered[, 3:10] <- lapply(weather_filtered[, 3:10], as.numeric)
nas <- colSums(is.na(weather_filtered))
print(nas/nrow(weather_filtered)*100)
# remove HourlyPressureChange, HourlyPressureTendency, HourlyWindGustSpeed because of high percentage of NAs
weather_filtered <- weather_filtered %>%
select(-HourlyPressureChange,-HourlyPressureTendency,-HourlyWindGustSpeed)
# fill remaining NAs using linear interpolation
na_columns <- colnames(weather_filtered)[colSums(is.na(weather_filtered)) > 0]
weather_filtered[na_columns] <- na.approx(weather_filtered[na_columns])
#check_nas <- colSums(is.na(weather_filtered))
#print(check_nas)
# still 4 rows of NAs, remove because low number and entire rows are NA
weather_filtered <- na.omit(weather_filtered)
check_nas <- colSums(is.na(weather_filtered))
print(check_nas)
# create date and hour columns
split_datetime <- strsplit(demand$Category, " ")
demand$date <- sapply(split_datetime, "[[", 1)
demand$hour <- sapply(split_datetime, "[[", 2)
demand$hour <- gsub("H", "", demand$hour)
demand <- demand %>% select(-Category)
#convert data and hour column to same format as weather_dh
demand_date <- demand %>%
mutate(date = format(as.Date(date, format = "%m/%d/%Y"), format = "%Y-%m-%d"))
#check for NAs
print(colSums(is.na(demand)))
# identify outliers
Q1 <- quantile(demand_date$MWh, 0.25)
Q3 <- quantile(demand_date$MWh, 0.75)
IQR <- Q3 - Q1
threshold <- 1.5
low_outliers <- demand_date[demand_date$MWh < (Q1 - threshold * IQR), ]
# use linear interpolation to fill 0 values
demand_date$MWh[demand_date$MWh == 0] <- NA
demand_date$MWh <- na.approx(demand_date$MWh)
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
demand_date$DateTime <- ymd(demand_date$date) + hours(demand_date$hour - 1)
# identify outliers
Q1 <- quantile(demand_date$MWh, 0.25)
Q3 <- quantile(demand_date$MWh, 0.75)
IQR <- Q3 - Q1
threshold <- 1.5
low_outliers <- demand_date[demand_date$MWh < (Q1 - threshold * IQR), ]
# use linear interpolation to fill 0 values
demand_date$MWh[demand_date$MWh == 0] <- NA
demand_date$MWh <- na.approx(demand_date$MWh)
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
demand_plot <- demand_date
demand_plot$DateTime <- ymd(demand_plot$date) + hours(demand_plot$hour - 1)
View(demand_plot)
library(tidyverse)
library(lubridate)
library(rpart)
library(rpart.plot)
library(gbm)
library(dplyr)
library(randomForest)
library(xgboost)
library(caret)
master <- read.csv("master.csv") %>% select(-X)
View(master)
# identify outliers
Q1 <- quantile(demand_date$MWh, 0.25)
Q3 <- quantile(demand_date$MWh, 0.75)
IQR <- Q3 - Q1
threshold <- 1.5
low_outliers <- demand_date[demand_date$MWh < (Q1 - threshold * IQR), ]
# use linear interpolation to fill 0 values
demand_date$MWh[demand_date$MWh == 0] <- NA
demand_date$MWh <- na.approx(demand_date$MWh)
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
demand_plot <- demand_date
demand_plot$hour <- as.numeric(demand_plot$hour)
demand_plot$DateTime <- ymd(demand_plot$date) + hours(demand_plot$hour - 1)
demand_plot <- demand_plot %>% select(-date,-hour)
#ggplot(demand_date, )
# remove low outliers
#demand_out <- demand_date[demand_date$MWh >= (Q1 - threshold * IQR), ]
ggplot(demand_plot, aes(x = DateTime, y = MWh)) +
geom_line() +
labs(x = "Datetime", y = "MWh", title = "MWh over Time")
ggplot(demand_plot, aes(x = DateTime, y = MWh)) +
geom_line() +
labs(x = "Datetime", y = "MWh", title = "New York City Electrcity Demand (MWh) (July 2015- November 2022)")
combined_df <- rbind(demand_plot, high_outliers)
combined_df <- rbind(demand_date, high_outliers)
View(combined_df)
high_outliers$source <- "high_outliers"
demand_plot <- demand_date
demand_plot$source <- "NYC_Elec"
demand_plot <- rbind(demand_plot, high_outliers)
demand_plot$hour <- as.numeric(demand_plot$hour)
demand_plot$DateTime <- ymd(demand_plot$date) + hours(demand_plot$hour - 1)
demand_plot <- demand_plot %>% select(-date,-hour)
ggplot(demand_plot, aes(x = DateTime, y = MWh, colour = source)) +
geom_line() +
labs(x = "Datetime", y = "MWh", title = "New York City Hourly Electrcity Demand (MWh) (July 2015 - November 2022)") +
scale_color_manual(values = c("red", "blue"))
View(combined_df)
View(demand_plot)
View(demand_plot)
Q1 <- quantile(demand_date$MWh, 0.25)
Q3 <- quantile(demand_date$MWh, 0.75)
IQR <- Q3 - Q1
threshold <- 1.5
low_outliers <- demand_date[demand_date$MWh < (Q1 - threshold * IQR), ]
# use linear interpolation to fill 0 values
demand_date$MWh[demand_date$MWh == 0] <- NA
demand_date$MWh <- na.approx(demand_date$MWh)
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- demand_date
demand_plot$source <- "NYC_Elec"
combined_df <- left_join(demand_date, high_outliers, by = c("MWh", "DateTime"), suffix = c("_NYC_Elec", "_high_outliers"))
library(tidyverse)
library(tidyr)
library(dplyr)
library(zoo)
library(lubridate)
library(ggplot2)
library(corrplot)
wd <- "C:/Users/wwell/Documents/GitHub/demand_prediction_local/data/"
weather <- read.csv(paste0 (wd, "NOAA_New York_Weather Data.csv"))
demand <- read.csv(paste0 (wd, "Demand_for_New_York_Independent_System_Operator_(NYIS)_hourly_-_UTC_time.csv"), skip=4)
#print(colnames(weather))
weather_filtered <- weather %>%
select(-starts_with("Daily"), -starts_with("Monthly"), -starts_with("ShortDuration"),-starts_with("Backup")) %>%
select(-c(1,3:13,17,21,22,26,29:36))
print(colnames(weather_filtered))
# create date and hour columns
weather_filtered <- weather_filtered %>%
separate(DATE, into = c("date", "hour"), sep = "T")
weather_filtered$hour <- substr(weather_filtered$hour, 1, 2)
# remove duplicates for the date and hour columns
weather_filtered <- weather_filtered[!duplicated(weather_filtered[, c("date", "hour")], fromFirst = TRUE), ]
# convert columns to numeric
weather_filtered[, 3:10] <- lapply(weather_filtered[, 3:10], as.numeric)
nas <- colSums(is.na(weather_filtered))
print(nas/nrow(weather_filtered)*100)
# remove HourlyPressureChange, HourlyPressureTendency, HourlyWindGustSpeed because of high percentage of NAs
weather_filtered <- weather_filtered %>%
select(-HourlyPressureChange,-HourlyPressureTendency,-HourlyWindGustSpeed)
# fill remaining NAs using linear interpolation
na_columns <- colnames(weather_filtered)[colSums(is.na(weather_filtered)) > 0]
weather_filtered[na_columns] <- na.approx(weather_filtered[na_columns])
#check_nas <- colSums(is.na(weather_filtered))
#print(check_nas)
# still 4 rows of NAs, remove because low number and entire rows are NA
weather_filtered <- na.omit(weather_filtered)
check_nas <- colSums(is.na(weather_filtered))
print(check_nas)
# create date and hour columns
split_datetime <- strsplit(demand$Category, " ")
demand$date <- sapply(split_datetime, "[[", 1)
demand$hour <- sapply(split_datetime, "[[", 2)
demand$hour <- gsub("H", "", demand$hour)
demand <- demand %>% select(-Category)
#convert data and hour column to same format as weather_dh
demand_date <- demand %>%
mutate(date = format(as.Date(date, format = "%m/%d/%Y"), format = "%Y-%m-%d"))
#check for NAs
print(colSums(is.na(demand)))
View(demand_date)
Q1 <- quantile(demand_date$MWh, 0.25)
Q3 <- quantile(demand_date$MWh, 0.75)
IQR <- Q3 - Q1
threshold <- 1.5
low_outliers <- demand_date[demand_date$MWh < (Q1 - threshold * IQR), ]
# use linear interpolation to fill 0 values
demand_date$MWh[demand_date$MWh == 0] <- NA
demand_date$MWh <- na.approx(demand_date$MWh)
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
View(high_outliers)
# plot high outliers and normal
high_outliers$source <- "high_outliers"
View(high_outliers)
library(tidyverse)
library(tidyr)
library(dplyr)
library(zoo)
library(lubridate)
library(ggplot2)
library(corrplot)
wd <- "C:/Users/wwell/Documents/GitHub/demand_prediction_local/data/"
weather <- read.csv(paste0 (wd, "NOAA_New York_Weather Data.csv"))
demand <- read.csv(paste0 (wd, "Demand_for_New_York_Independent_System_Operator_(NYIS)_hourly_-_UTC_time.csv"), skip=4)
#print(colnames(weather))
weather_filtered <- weather %>%
select(-starts_with("Daily"), -starts_with("Monthly"), -starts_with("ShortDuration"),-starts_with("Backup")) %>%
select(-c(1,3:13,17,21,22,26,29:36))
print(colnames(weather_filtered))
# create date and hour columns
weather_filtered <- weather_filtered %>%
separate(DATE, into = c("date", "hour"), sep = "T")
weather_filtered$hour <- substr(weather_filtered$hour, 1, 2)
# remove duplicates for the date and hour columns
weather_filtered <- weather_filtered[!duplicated(weather_filtered[, c("date", "hour")], fromFirst = TRUE), ]
# convert columns to numeric
weather_filtered[, 3:10] <- lapply(weather_filtered[, 3:10], as.numeric)
nas <- colSums(is.na(weather_filtered))
print(nas/nrow(weather_filtered)*100)
# remove HourlyPressureChange, HourlyPressureTendency, HourlyWindGustSpeed because of high percentage of NAs
weather_filtered <- weather_filtered %>%
select(-HourlyPressureChange,-HourlyPressureTendency,-HourlyWindGustSpeed)
# fill remaining NAs using linear interpolation
na_columns <- colnames(weather_filtered)[colSums(is.na(weather_filtered)) > 0]
weather_filtered[na_columns] <- na.approx(weather_filtered[na_columns])
#check_nas <- colSums(is.na(weather_filtered))
#print(check_nas)
# still 4 rows of NAs, remove because low number and entire rows are NA
weather_filtered <- na.omit(weather_filtered)
check_nas <- colSums(is.na(weather_filtered))
print(check_nas)
# create date and hour columns
split_datetime <- strsplit(demand$Category, " ")
demand$date <- sapply(split_datetime, "[[", 1)
demand$hour <- sapply(split_datetime, "[[", 2)
demand$hour <- gsub("H", "", demand$hour)
demand <- demand %>% select(-Category)
#convert data and hour column to same format as weather_dh
demand_date <- demand %>%
mutate(date = format(as.Date(date, format = "%m/%d/%Y"), format = "%Y-%m-%d"))
#check for NAs
print(colSums(is.na(demand)))
# identify outliers
Q1 <- quantile(demand_date$MWh, 0.25)
Q3 <- quantile(demand_date$MWh, 0.75)
IQR <- Q3 - Q1
threshold <- 1.5
low_outliers <- demand_date[demand_date$MWh < (Q1 - threshold * IQR), ]
# use linear interpolation to fill 0 values
demand_date$MWh[demand_date$MWh == 0] <- NA
demand_date$MWh <- na.approx(demand_date$MWh)
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- copy(demand_date)
demand_plot <- base::copy(demand_date)
demand_plot <- data.frame(demand_date)
View(demand_plot)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_date, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
#high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
#demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
View(high_outliers)
# plot high outliers and normal
#high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
#demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
View(demand_plot)
# plot high outliers and normal
#high_outliers$source <- "high_outliers"
#demand_plot <- data.frame(demand_date)
#demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_date, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
View(demand_plot)
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
demand_plot <- demand_plot %>% filter(!is.na(MWh_high_outliers))
demand_plot <- demand_plot %>% filter(!is.na(source_high_outliers))
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
demand_plot <- demand_plot %>%
mutate(new_column = ifelse(is.na(source_NTC_Elec), high_outliers, NTC_Elec))
demand_plot <- demand_plot %>%
mutate(new_column = ifelse(is.na(source_NTC_Elec), source_high_outliers, source_NTC_Elec))
demand_plot <- demand_plot %>%
mutate(new_column = ifelse(is.na(source_NYC_Elec), source_high_outliers, source_NYC_Elec))
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
demand_plot <- demand_plot %>%
mutate(source = ifelse(is.na(source_NYC_Elec), source_high_outliers, source_NYC_Elec))
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
demand_plot <- demand_plot %>%
mutate(source = ifelse(is.na(source_NYC_Elec), source_high_outliers, source_NYC_Elec)) %>%
select(-source_NYC_Elec, source_high_outliers)
demand_plot <- demand_plot %>%
mutate(source = ifelse(is.na(source_NYC_Elec), source_high_outliers, source_NYC_Elec)) %>%
select(-source_NYC_Elec, -source_high_outliers)
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
demand_plot <- demand_plot %>%
mutate(source = ifelse(is.na(source_NYC_Elec), source_high_outliers, source_NYC_Elec)) %>%
select(-source_NYC_Elec, -source_high_outliers)
demand_plot$hour <- as.numeric(demand_plot$hour)
demand_plot$DateTime <- ymd(demand_plot$date) + hours(demand_plot$hour - 1)
demand_plot <- demand_plot %>% select(-date,-hour)
ggplot(demand_plot, aes(x = DateTime, y = MWh, colour = source)) +
geom_line() +
labs(x = "Datetime", y = "MWh", title = "New York City Hourly Electrcity Demand (MWh) (July 2015 - November 2022)") +
scale_color_manual(values = c("red", "blue"))
unique_values <- unique(demand_plot$source)
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
# identify high outliers
high_outliers <- demand_date[demand_date$MWh > (Q3 + threshold * IQR), ]
# plot high outliers and normal
high_outliers$source <- "high_outliers"
demand_plot <- data.frame(demand_date)
demand_plot$source <- "NYC_Elec"
demand_plot <- left_join(demand_plot, high_outliers, by = c("MWh", "date", "hour"), suffix = c("_NYC_Elec", "_high_outliers"))
demand_plot <- demand_plot %>%
mutate(source = ifelse(is.na(source_high_outliers), source_NYC_Elec, source_high_outliers)) %>%
select(-source_NYC_Elec, -source_high_outliers)
demand_plot$hour <- as.numeric(demand_plot$hour)
demand_plot$DateTime <- ymd(demand_plot$date) + hours(demand_plot$hour - 1)
demand_plot <- demand_plot %>% select(-date,-hour)
unique_values <- unique(demand_plot$source)
ggplot(demand_plot, aes(x = DateTime, y = MWh, colour = source)) +
geom_line() +
labs(x = "Datetime", y = "MWh", title = "New York City Hourly Electrcity Demand (MWh) (July 2015 - November 2022)") +
scale_color_manual(values = c("red", "blue"))
demand_plot <- demand_plot %>%
arrange(source, DateTime)
unique_values <- unique(demand_plot$source)
ggplot(demand_plot, aes(x = DateTime, y = MWh, colour = source)) +
geom_line() +
labs(x = "Datetime", y = "MWh", title = "New York City Hourly Electrcity Demand (MWh) (July 2015 - November 2022)") +
scale_color_manual(values = c("red", "blue"))
ggplot(demand_plot, aes(x = DateTime, y = MWh, colour = source, group = 1)) +
geom_line() +
labs(x = "Datetime", y = "MWh", title = "New York City Hourly Electrcity Demand (MWh) (July 2015 - November 2022)") +
scale_color_manual(values = c("red", "blue"))
master <- merge(weather_filtered, demand_date, by.x = c("date", "hour"), by.y = c("date", "hour"), all = FALSE)
View(master)
#find out how many days per year
year_count <- master %>%
mutate(year = year(date),
day_of_year = yday(date))
count_unique_days_per_year <- year_count %>%
group_by(year) %>%
summarize(unique_days_count = n_distinct(day_of_year))
print(count_unique_days_per_year)
master <- master %>%
filter(year(date) %in% c(2016, 2017, 2018, 2019))
#check most days have 24hrs
number_24hrs <- table(table(master$date))
#yes majority do
# add days of the week
master$date <- as.Date(master$date)
master$dayofweek <- weekdays(master$date)
master$weekdayorweekend <- ifelse(master$dayofweek %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
master <- master %>% select(-dayofweek)
#add season
season_func <- function(date) {
month <- as.integer(format(date, "%m"))
if (month >= 3 && month <= 5) {
return("Spring")
} else if (month >= 6 && month <= 8) {
return("Summer")
} else if (month >= 9 && month <= 11) {
return("Autumn")
} else {
return("Winter")
}
}
master$season <- sapply(master$date, season_func)
#remove hourly reference from variable titles
colnames(master) <- sub("Hourly", "", colnames(master))
# add days of the week
master$date <- as.Date(master$date)
master$dayofweek <- weekdays(master$date)
master$weekdayorweekend <- ifelse(master$dayofweek %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
master <- master %>% select(-dayofweek)
#add season
season_func <- function(date) {
month <- as.integer(format(date, "%m"))
if (month >= 3 && month <= 5) {
return("Spring")
} else if (month >= 6 && month <= 8) {
return("Summer")
} else if (month >= 9 && month <= 11) {
return("Autumn")
} else {
return("Winter")
}
}
master$season <- sapply(master$date, season_func)
#remove hourly reference from variable titles
colnames(master) <- sub("Hourly", "", colnames(master))
#find out how many days per year
year_count <- master %>%
mutate(year = year(date),
day_of_year = yday(date))
count_unique_days_per_year <- year_count %>%
group_by(year) %>%
summarize(unique_days_count = n_distinct(day_of_year))
print(count_unique_days_per_year)
master <- master %>%
filter(year(date) %in% c(2016, 2017, 2018, 2019))
#check most days have 24hrs
number_24hrs <- table(table(master$date))
#yes majority do
