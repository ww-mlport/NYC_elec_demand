---
title: "Demand Prediction - data wrangling"
output: html_document
---
# Description
### Data scope:
New York City, 2016-2019, hourly electricity consumption (MWh), weather variables

### Data sources:
Weather: National Oceanic Atmospheric Association (NOAA)
Electricity demand: U.S. Energy Information Administration

### Aim:
1. Clean and format data for building machine learning models (remove irrelevant columns, remove NAs, fill in blanks, manage outliers)
2. Analyse covariance of variables

### Result notes:
Although the pearson correlation showed covariance between temperature variables in particular, it was decided not to remove them because of the potential for underlying predictive power of each temperature measurement depending upon season.

```{r, include=FALSE}
library(tidyverse)
library(tidyr)
library(dplyr)
library(zoo)
library(lubridate)
library(ggplot2)
library(corrplot)

weather <- read.csv("NOAA_New York_Weather Data.csv")
demand <- read.csv("Demand_for_New_York_Independent_System_Operator_(NYIS)_hourly_-_UTC_time.csv", skip=4)

```

## 1. Weather
View columns and remove irrelevant variables e.g. related to daily, monthly rather than hourly. Backup columns etc.

```{r}
#print(colnames(weather))
weather_filtered <- weather %>%
  select(-starts_with("Daily"), -starts_with("Monthly"), -starts_with("ShortDuration"),-starts_with("Backup")) %>%
  select(-c(1,3:13,17,21,22,26,29:36))
print(colnames(weather_filtered))
```
Create date and hour columns, remove duplicated dates/hours, convert columns to numeric

```{r, warning=FALSE}
# create date and hour columns
weather_filtered <- weather_filtered %>%
  separate(DATE, into = c("date", "hour"), sep = "T")
weather_filtered$hour <- substr(weather_filtered$hour, 1, 2)
# remove duplicates for the date and hour columns
weather_filtered <- weather_filtered[!duplicated(weather_filtered[, c("date", "hour")], fromFirst = TRUE), ]
# convert columns to numeric
weather_filtered[, 3:10] <- lapply(weather_filtered[, 3:10], as.numeric)
```
### 1.1 Weather NAs
Remove columns with too many NAs
Fill remaining NAs with linear interpolation

```{r}
nas <- colSums(is.na(weather_filtered))
print(nas/nrow(weather_filtered)*100)
# remove HourlyPressureChange, HourlyPressureTendency, HourlyWindGustSpeed because of high percentage of NAs
weather_filtered <- weather_filtered %>% 
  select(-HourlyPressureChange,-HourlyPressureTendency,-HourlyWindGustSpeed)
# fill remaining NAs using linear interpolation
na_columns <- colnames(weather_filtered)[colSums(is.na(weather_filtered)) > 0]
weather_filtered[na_columns] <- na.approx(weather_filtered[na_columns])
#check_nas <- colSums(is.na(weather_filtered))
#print(check_nas)
# still 4 rows of NAs, remove because low number and entire rows are NA
weather_filtered <- na.omit(weather_filtered)

check_nas <- colSums(is.na(weather_filtered))
print(check_nas)
```
## 2. Demand

Create date and hour columns in same format as weather_dh

```{r}
# create date and hour columns
split_datetime <- strsplit(demand$Category, " ")
demand$date <- sapply(split_datetime, "[[", 1)
demand$hour <- sapply(split_datetime, "[[", 2)
demand$hour <- gsub("H", "", demand$hour)
demand <- demand %>% select(-Category)

#convert data and hour column to same format as weather_dh
demand_date <- demand %>%
  mutate(date = format(as.Date(date, format = "%m/%d/%Y"), format = "%Y-%m-%d"))

```

### 2.1 NAs

No NAs found

```{r}
#check for NAs
print(colSums(is.na(demand)))
```

### 2.2 Outliers

Detect outliers using IQR. Remove extreme lower outliers

```{r}
# identify outliers
Q1 <- quantile(demand_date$MWh, 0.25)
Q3 <- quantile(demand_date$MWh, 0.75)
IQR <- Q3 - Q1
threshold <- 1.5
outliers <- demand_date[demand_date$MWh < (Q1 - threshold * IQR), ]
# remove low outliers
demand_out <- demand_date[demand_date$MWh >= (Q1 - threshold * IQR), ]
```


## 3. Merge datasets

```{r}
master <- merge(weather_filtered, demand_out, by.x = c("date", "hour"), by.y = c("date", "hour"), all = FALSE)
```

Check most days have 24hrs
Filter for only 2016, 2017, 2018 and 2019 to avoid COVID affected years
Add weekend/weekday and seasons variables

```{r}
#find out how many days per year
year_count <- master %>%
  mutate(year = year(date),
         day_of_year = yday(date))
count_unique_days_per_year <- year_count %>%
  group_by(year) %>%
  summarize(unique_days_count = n_distinct(day_of_year))
print(count_unique_days_per_year)

master <- master %>%
  filter(year(date) %in% c(2016, 2017, 2018, 2019))

#check most days have 24hrs
number_24hrs <- table(table(master$date))
#yes majority do

# add days of the week
master$date <- as.Date(master$date)
master$dayofweek <- weekdays(master$date)
master$weekdayorweekend <- ifelse(master$dayofweek %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
master <- master %>% select(-dayofweek)

#add season
season_func <- function(date) {
  month <- as.integer(format(date, "%m"))
  
  if (month >= 3 && month <= 5) {
    return("Spring")
  } else if (month >= 6 && month <= 8) {
    return("Summer")
  } else if (month >= 9 && month <= 11) {
    return("Autumn")
  } else {
    return("Winter")
  }
}
master$season <- sapply(master$date, season_func)
#remove hourly reference from variable titles
colnames(master) <- sub("Hourly", "", colnames(master))
```

## 4. Plots
### 4.1 Pearson Correlation Coefficent Matrix
Plot a correlation matrix to analyse linear relationships between numeric variables

```{r}
## create a pearson correlation matrix and plot
master_cor <- master %>% select(-date,-weekdayorweekend,-season)
master_cor$hour <- as.numeric(master_cor$hour)
cor_matrix <- round(cor(master_cor), 1)
corrplot(
  cor_matrix, 
  method = "color", 
  col = colorRampPalette(c("white", "red"))(100),
  type = "upper",    
  tl.col = "black",  
  tl.srt = 45,
  addCoef.col = "black",  
)
```

### 4.2 Variable Plots
View relationship between independent and dependent variables using scatter plots

```{r}

plots_list <- list()

for (i in 1:10) {
  p <- ggplot(master_cor, aes(x = master_cor[, 10], y = master_cor[, i])) +
    geom_point() +                    
    geom_smooth(method = "lm") +      
    labs(x = names(master_cor)[10], y = names(master_cor)[i]) +  
    ggtitle(paste(names(master_cor)[i], "vs.", names(master_cor)[10]))  
  
  plots_list[[i]] <- p
}

for (i in 1:length(plots_list)) {
  print(plots_list[[i]])
}
```

### 4.3 Perform ANOVA on categorical variables vs MWh

Result: the low p values suggest a statistically significant effect of these variables on the dependent variable.

```{r}
# perform ANOVA analysis for the categorical variables
anova_weekdayorweekend <- aov(MWh ~ weekdayorweekend, data = master)
anova_season <- aov(MWh ~ season, data = master)
print(summary(anova_weekdayorweekend))
print(summary(anova_season))
```

